import cv2
import time
import threading
import queue
import numpy as np
from modules.state import initialize_states
from modules.detection import yolo_to_deepsort
from modules.fsm import update_states
from modules.visualize import drawing
from modules.sort_tracker import track_with_sort
from modules.clean_bbox import rm_duplicate

MODEL_PATH = "picnic_5n_fp16.engine"
VIDEO_PATH = "input.mp4"
BUFFER_SIZE = 1

def yolo_worker(frame_q: queue.Queue, result_dict: dict):
    from modules.detect import TRTInfer 
    model = TRTInfer(MODEL_PATH)        

    states = initialize_states()

    while True:
        item = frame_q.get()
        if item is None:
            break

        frame, orig_fps = item

        raw_detections = model.infer(frame)
        detections = yolo_to_deepsort(raw_detections)

        det_person = rm_duplicate([d[:5] for d in detections if d[5] == "person"], 20, "max_conf")
        det_mat    = rm_duplicate([d[:5] for d in detections if d[5] == "mat"],    20, "max_conf")
        det_bottle = rm_duplicate([d[:5] for d in detections if d[5] == "bottle"], 20, "max_conf")

        trk_person = track_with_sort(det_person, "person")
        trk_mat    = track_with_sort(det_mat,    "mat")
        trk_bottle = track_with_sort(det_bottle, "bottle")

        person_bb = [(tid, (x1, y1, x2, y2)) for x1, y1, x2, y2, tid in trk_person]
        mat_bb    = [(tid, (x1, y1, x2, y2)) for x1, y1, x2, y2, tid in trk_mat]
        bottle_bb = [(tid, (x1, y1, x2, y2)) for x1, y1, x2, y2, tid in trk_bottle]

        update_states(states, person_bb, mat_bb, bottle_bb, orig_fps)

        result_dict["bboxes"] = (person_bb, mat_bb, bottle_bb)
        result_dict["states"] = states.copy()

def main():
    cap = cv2.VideoCapture(VIDEO_PATH)
    if not cap.isOpened():
        raise RuntimeError(f" Cannot open video source: {VIDEO_PATH}")

    orig_fps = cap.get(cv2.CAP_PROP_FPS)
    if orig_fps == 0 or np.isnan(orig_fps):
        orig_fps = 30
    frame_interval = 1.0 / orig_fps

    # ìœˆë„ìš°ë¥¼ í•œ ë²ˆë§Œ ìƒì„±í•˜ê³  í¬ê¸° ì¡°ì •
    window_name = "ğŸ§º Picnic Trash Detection â€“ Realtime"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 1280, 720)
    # ì „ì²´í™”ë©´ìœ¼ë¡œ í‘œì‹œí•˜ë ¤ë©´ ì•„ë˜ë¥¼ ëŒ€ì‹  ì‚¬ìš©í•˜ì„¸ìš”:
    # cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

    frame_q = queue.Queue(maxsize=BUFFER_SIZE)
    result_dict = {"bboxes": ([], [], []), "states": {}}

    worker = threading.Thread(target=yolo_worker, args=(frame_q, result_dict), daemon=True)
    worker.start()

    prev_time = time.time()

    while True:
        ret, frame = cap.read()
        if not ret:
            print(" Video read failed.")
            break

        # ìµœì‹  í”„ë ˆì„ë§Œ íì— ìœ ì§€
        if not frame_q.empty():
            try:
                frame_q.get_nowait()
            except queue.Empty:
                pass
        frame_q.put((frame.copy(), orig_fps))

        person_bb, mat_bb, bottle_bb = result_dict.get("bboxes", ([], [], []))
        states = result_dict.get("states", {})
        drawing(frame, person_bb, mat_bb, bottle_bb, states)

        # í•­ìƒ ê°™ì€ ìœˆë„ìš° ì´ë¦„ ì‚¬ìš©
        cv2.imshow(window_name, frame)

        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

        # ì¬ìƒ ì†ë„ ì¡°ì ˆ
        elapsed = time.time() - prev_time
        if elapsed < frame_interval:
            time.sleep(frame_interval - elapsed)
        prev_time = time.time()

    # ì›Œì»¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ
    frame_q.put(None)
    worker.join()
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()



